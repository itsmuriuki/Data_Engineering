{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: ETL Pipeline for Preprocessing the Files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import python packages\n",
    "import os\n",
    "import re \n",
    "import csv\n",
    "import glob\n",
    "import json\n",
    "import cassandra\n",
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a list of filepaths to process original event csv data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/itsmuriuki/Desktop/Data_Engineering/Data_Modeling/project_2_NoSQL_Apache_Cassandra\n"
     ]
    }
   ],
   "source": [
    "# check your current working directory\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/itsmuriuki/Desktop/Data_Engineering/Data_Modeling/project_2_NoSQL_Apache_Cassandra/event_data'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get your current folder and sub folder event data \n",
    "filepath = os.getcwd() + '/event_data'\n",
    "filepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/Users/itsmuriuki/Desktop/Data_Engineering/Data_Modeling/project_2_NoSQL_Apache_Cassandra/event_data/2018-11-15-events.csv', '/Users/itsmuriuki/Desktop/Data_Engineering/Data_Modeling/project_2_NoSQL_Apache_Cassandra/event_data/2018-11-22-events.csv', '/Users/itsmuriuki/Desktop/Data_Engineering/Data_Modeling/project_2_NoSQL_Apache_Cassandra/event_data/2018-11-09-events.csv', '/Users/itsmuriuki/Desktop/Data_Engineering/Data_Modeling/project_2_NoSQL_Apache_Cassandra/event_data/2018-11-18-events.csv', '/Users/itsmuriuki/Desktop/Data_Engineering/Data_Modeling/project_2_NoSQL_Apache_Cassandra/event_data/2018-11-04-events.csv', '/Users/itsmuriuki/Desktop/Data_Engineering/Data_Modeling/project_2_NoSQL_Apache_Cassandra/event_data/2018-11-01-events.csv', '/Users/itsmuriuki/Desktop/Data_Engineering/Data_Modeling/project_2_NoSQL_Apache_Cassandra/event_data/2018-11-27-events.csv', '/Users/itsmuriuki/Desktop/Data_Engineering/Data_Modeling/project_2_NoSQL_Apache_Cassandra/event_data/2018-11-10-events.csv', '/Users/itsmuriuki/Desktop/Data_Engineering/Data_Modeling/project_2_NoSQL_Apache_Cassandra/event_data/2018-11-20-events.csv', '/Users/itsmuriuki/Desktop/Data_Engineering/Data_Modeling/project_2_NoSQL_Apache_Cassandra/event_data/2018-11-17-events.csv', '/Users/itsmuriuki/Desktop/Data_Engineering/Data_Modeling/project_2_NoSQL_Apache_Cassandra/event_data/2018-11-06-events.csv', '/Users/itsmuriuki/Desktop/Data_Engineering/Data_Modeling/project_2_NoSQL_Apache_Cassandra/event_data/2018-11-03-events.csv', '/Users/itsmuriuki/Desktop/Data_Engineering/Data_Modeling/project_2_NoSQL_Apache_Cassandra/event_data/2018-11-28-events.csv', '/Users/itsmuriuki/Desktop/Data_Engineering/Data_Modeling/project_2_NoSQL_Apache_Cassandra/event_data/2018-11-12-events.csv', '/Users/itsmuriuki/Desktop/Data_Engineering/Data_Modeling/project_2_NoSQL_Apache_Cassandra/event_data/2018-11-25-events.csv', '/Users/itsmuriuki/Desktop/Data_Engineering/Data_Modeling/project_2_NoSQL_Apache_Cassandra/event_data/2018-11-26-events.csv', '/Users/itsmuriuki/Desktop/Data_Engineering/Data_Modeling/project_2_NoSQL_Apache_Cassandra/event_data/2018-11-11-events.csv', '/Users/itsmuriuki/Desktop/Data_Engineering/Data_Modeling/project_2_NoSQL_Apache_Cassandra/event_data/2018-11-14-events.csv', '/Users/itsmuriuki/Desktop/Data_Engineering/Data_Modeling/project_2_NoSQL_Apache_Cassandra/event_data/2018-11-23-events.csv', '/Users/itsmuriuki/Desktop/Data_Engineering/Data_Modeling/project_2_NoSQL_Apache_Cassandra/event_data/2018-11-08-events.csv', '/Users/itsmuriuki/Desktop/Data_Engineering/Data_Modeling/project_2_NoSQL_Apache_Cassandra/event_data/2018-11-19-events.csv', '/Users/itsmuriuki/Desktop/Data_Engineering/Data_Modeling/project_2_NoSQL_Apache_Cassandra/event_data/2018-11-05-events.csv', '/Users/itsmuriuki/Desktop/Data_Engineering/Data_Modeling/project_2_NoSQL_Apache_Cassandra/event_data/2018-11-02-events.csv', '/Users/itsmuriuki/Desktop/Data_Engineering/Data_Modeling/project_2_NoSQL_Apache_Cassandra/event_data/2018-11-29-events.csv', '/Users/itsmuriuki/Desktop/Data_Engineering/Data_Modeling/project_2_NoSQL_Apache_Cassandra/event_data/2018-11-13-events.csv', '/Users/itsmuriuki/Desktop/Data_Engineering/Data_Modeling/project_2_NoSQL_Apache_Cassandra/event_data/2018-11-24-events.csv', '/Users/itsmuriuki/Desktop/Data_Engineering/Data_Modeling/project_2_NoSQL_Apache_Cassandra/event_data/2018-11-21-events.csv', '/Users/itsmuriuki/Desktop/Data_Engineering/Data_Modeling/project_2_NoSQL_Apache_Cassandra/event_data/2018-11-16-events.csv', '/Users/itsmuriuki/Desktop/Data_Engineering/Data_Modeling/project_2_NoSQL_Apache_Cassandra/event_data/2018-11-07-events.csv', '/Users/itsmuriuki/Desktop/Data_Engineering/Data_Modeling/project_2_NoSQL_Apache_Cassandra/event_data/2018-11-30-events.csv']\n"
     ]
    }
   ],
   "source": [
    "# create a for loop to create a list of files and collect each filepath\n",
    "for root, dirs, files in os.walk(filepath):\n",
    "    #join the file path and roots with the subdirectories using glob\n",
    "    file_path_list = glob.glob(os.path.join(root, '*'))\n",
    "    print(file_path_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing the files to create the data file csv that will be used for apache cassandra tables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8056\n"
     ]
    }
   ],
   "source": [
    "#initiating an empty list of rows that will be generated from each file \n",
    "full_data_rows_list = []\n",
    "\n",
    "# for every filepath in the file path list \n",
    "for f in file_path_list:\n",
    "    \n",
    "    #read csv file\n",
    "    with open(f,'r', encoding='utf8', newline='') as csvfile:\n",
    "        #creating a csv reader object\n",
    "        csvreader = csv.reader(csvfile)\n",
    "        next (csvreader)\n",
    "        \n",
    "        #extracting each data row, one by one and appending it\n",
    "        for line in csvreader:\n",
    "            #print(line)\n",
    "            full_data_rows_list.append(line)\n",
    "            \n",
    "#getting the total number of rows\n",
    "print(len(full_data_rows_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# looking at list of event data \n",
    "# print(full_data_rows_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating one event_datafile_new.csv file to write from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a smaller event data csv file called event_datafile_ful.csv that will be used to insert data into the \n",
    "# Apache casandra tables \n",
    "csv.register_dialect('myDialect', quoting=csv.QUOTE_ALL, skipinitialspace=True)\n",
    "\n",
    "with open('event_datafile_new.csv', 'w', encoding='utf8', newline='') as f:\n",
    "    writer= csv.writer(f, dialect='myDialect')\n",
    "    writer.writerow(['artist','firstName','gender','itemInSession','lastName','length',\\\n",
    "                'level','location','sessionId','song','userId'])\n",
    "    for row in full_data_rows_list:\n",
    "        if (row[0] == ''):\n",
    "            continue\n",
    "        writer.writerow((row[0], row[2], row[3], row[4], row[5], row[6], row[7], row[8], row[12], row[13], row[16]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6821\n"
     ]
    }
   ],
   "source": [
    "#check the number of rows in csv file\n",
    "with open('event_datafile_new.csv', 'r', encoding='utf8') as f:\n",
    "    print(sum(1 for line in f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2. Coding the Apache Cassandra part of things"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now going to work with the *event_datafile_new.csv* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's have a look at it \n",
    "df = pd.read_csv('event_datafile_new.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>firstName</th>\n",
       "      <th>gender</th>\n",
       "      <th>itemInSession</th>\n",
       "      <th>lastName</th>\n",
       "      <th>length</th>\n",
       "      <th>level</th>\n",
       "      <th>location</th>\n",
       "      <th>sessionId</th>\n",
       "      <th>song</th>\n",
       "      <th>userId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Harmonia</td>\n",
       "      <td>Ryan</td>\n",
       "      <td>M</td>\n",
       "      <td>0</td>\n",
       "      <td>Smith</td>\n",
       "      <td>655.77751</td>\n",
       "      <td>free</td>\n",
       "      <td>San Jose-Sunnyvale-Santa Clara, CA</td>\n",
       "      <td>583</td>\n",
       "      <td>Sehr kosmisch</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Prodigy</td>\n",
       "      <td>Ryan</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "      <td>Smith</td>\n",
       "      <td>260.07465</td>\n",
       "      <td>free</td>\n",
       "      <td>San Jose-Sunnyvale-Santa Clara, CA</td>\n",
       "      <td>583</td>\n",
       "      <td>The Big Gundown</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Train</td>\n",
       "      <td>Ryan</td>\n",
       "      <td>M</td>\n",
       "      <td>2</td>\n",
       "      <td>Smith</td>\n",
       "      <td>205.45261</td>\n",
       "      <td>free</td>\n",
       "      <td>San Jose-Sunnyvale-Santa Clara, CA</td>\n",
       "      <td>583</td>\n",
       "      <td>Marry Me</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sony Wonder</td>\n",
       "      <td>Samuel</td>\n",
       "      <td>M</td>\n",
       "      <td>0</td>\n",
       "      <td>Gonzalez</td>\n",
       "      <td>218.06975</td>\n",
       "      <td>free</td>\n",
       "      <td>Houston-The Woodlands-Sugar Land, TX</td>\n",
       "      <td>597</td>\n",
       "      <td>Blackbird</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Van Halen</td>\n",
       "      <td>Tegan</td>\n",
       "      <td>F</td>\n",
       "      <td>2</td>\n",
       "      <td>Levine</td>\n",
       "      <td>289.38404</td>\n",
       "      <td>paid</td>\n",
       "      <td>Portland-South Portland, ME</td>\n",
       "      <td>602</td>\n",
       "      <td>Best Of Both Worlds (Remastered Album Version)</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        artist firstName gender  itemInSession  lastName     length level  \\\n",
       "0     Harmonia      Ryan      M              0     Smith  655.77751  free   \n",
       "1  The Prodigy      Ryan      M              1     Smith  260.07465  free   \n",
       "2        Train      Ryan      M              2     Smith  205.45261  free   \n",
       "3  Sony Wonder    Samuel      M              0  Gonzalez  218.06975  free   \n",
       "4    Van Halen     Tegan      F              2    Levine  289.38404  paid   \n",
       "\n",
       "                               location  sessionId  \\\n",
       "0    San Jose-Sunnyvale-Santa Clara, CA        583   \n",
       "1    San Jose-Sunnyvale-Santa Clara, CA        583   \n",
       "2    San Jose-Sunnyvale-Santa Clara, CA        583   \n",
       "3  Houston-The Woodlands-Sugar Land, TX        597   \n",
       "4           Portland-South Portland, ME        602   \n",
       "\n",
       "                                             song  userId  \n",
       "0                                   Sehr kosmisch      26  \n",
       "1                                 The Big Gundown      26  \n",
       "2                                        Marry Me      26  \n",
       "3                                       Blackbird      61  \n",
       "4  Best Of Both Worlds (Remastered Album Version)      80  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['artist', 'firstName', 'gender', 'itemInSession', 'lastName', 'length',\n",
       "       'level', 'location', 'sessionId', 'song', 'userId'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#the columns in the event_datafile_new.csv\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing the Apache Cassandra code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### creating a cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cassandra.cluster import Cluster\n",
    "# from cassandra.policies import DCAwareRoundRobinPolicy\n",
    "# from cassandra.auth import PlainTextAuthProvider\n",
    "\n",
    "#connecting to local cluster\n",
    "try:\n",
    "    cluster = Cluster()\n",
    "    # To establish connection and begin executing queries, need a session\n",
    "    session = cluster.connect()\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "\n",
    "# credentials would be different when connecting to a different instance.\n",
    "# def cassandra_conn():\n",
    "\n",
    "#    auth_provider = PlainTextAuthProvider(username='cassandra', password='password')\n",
    "#    cluster = Cluster(['127.0.0.1'], load_balancing_policy=DCAwareRoundRobinPolicy(local_dc='US-WEST'), port=9042, auth_provider=auth_provider)\n",
    "\n",
    "#    session = cluster.connect()\n",
    "\n",
    "#    return session, cluster\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Keyspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_keyspace_command = \"\"\"CREATE KEYSPACE IF NOT EXISTS sparkify\n",
    "                             WITH REPLICATION = { 'class' : 'SimpleStrategy', 'replication_factor' : 1 }\"\"\"\n",
    "\n",
    "try:\n",
    "    session.execute(create_keyspace_command)\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set Keyspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_keyspace_command = \"USE sparkify\"\n",
    "\n",
    "try:\n",
    "    session.execute(set_keyspace_command)\n",
    "except Exceptionption as e:\n",
    "    print(e)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# part 3: Modelling the database on the queries given"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to create tables to run the following queries. Remember, with Apache Cassandra you model the database tables on the queries you want to run.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create queries to ask the following three questions of the data\n",
    "1. Give me the artist, song title and song's length in the music app history that was heard during sessionId = 338, and itemInSession = 4\n",
    "2. Give me only the following: name of artist, song (sorted by itemInSession) and user (first and last name) for userid = 10, sessionid = 182\n",
    "3. Give me every user name (first and last) in my music app history who listened to the song 'All Hands Against His Own'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. Give me the artist, song title and song's length in the music app history that was heard during \n",
    "#sessionId = 338, and itemInSession = 4\n",
    "\n",
    "# we will use seessionId and itemSession\n",
    "# Our complete PRIMARY KEY is composed by session_id, session_item_number\n",
    "\n",
    "create_statement = \"\"\"CREATE TABLE IF NOT EXISTS song_data_by_session(session_id INT,\n",
    "                    session_item_number INT,\n",
    "                    artist_name TEXT,\n",
    "                    song_title TEXT,\n",
    "                    song_length DOUBLE,\n",
    "                    PRIMARY KEY((session_id, session_item_number))) \"\"\"\n",
    "\n",
    "session.execute(create_statement)\n",
    "\n",
    "select_statement = \"SELECT artist_name, song_title, song_length FROM song_data_by_session WHERE session_id = %s AND session_item_number = %s\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting up the csv file \n",
    "file = 'event_datafile_new.csv'\n",
    "\n",
    "with open(file, encoding= 'utf8') as f:\n",
    "    csvreader = csv.reader(f)\n",
    "    next(csvreader) #skip header\n",
    "    for line in csvreader:\n",
    "        query = \"\"\"INSERT INTO song_data_by_session(session_id, session_item_number, artist_name, song_title, song_length)\"\"\"\n",
    "        query= query + \"VALUES (%s, %s, %s, %s, %s )\"\n",
    "        \n",
    "        session.execute(query, (int(line[8]), int(line[3]), line[0], line[9], float(line[5])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Do a SELECT to verify that the data has been inserted into each table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row(artist_name='Faithless', song_title='Music Matters (Mark Knight Dub)', song_length=495.3073)\n"
     ]
    }
   ],
   "source": [
    "# Add in the SELECT statement to verify the data was entered into the table\n",
    "result_set = session.execute(select_statement, (338, 4))\n",
    "\n",
    "for row in result_set:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "copy and paste the above three cells for the rest of the queries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. Give me only the following: name of artist, song (sorted by itemInSession) and user (first and last name)\n",
    "# for userid = 10, sessionid = 182\n",
    "\n",
    "\n",
    "## In this case user_id and session_id are the COMPOUND PARTITION KEY  \\\n",
    "## this allows us to have a unique PRIMARY KEY for our query, but for this request we have to \\\n",
    "## order by session_item_number but not to query on that so we have to declare session_item_number as CLUSTERING KEY. \\\n",
    "## Our complete PRIMARY KEY is composed by user_id, session_id, session_item_numbe\n",
    "\n",
    "create_statement = \"\"\"CREATE TABLE IF NOT EXISTS song_user_data_by_user_and_session_data(user_id INT,\n",
    "                    session_id INT,\n",
    "                    session_item_number INT,\n",
    "                    artist_name TEXT,\n",
    "                    song_title TEXT,\n",
    "                    user_first_name TEXT,\n",
    "                    user_last_name TEXT,\n",
    "                    PRIMARY KEY ((user_id,session_id), session_item_number))\"\"\"\n",
    "\n",
    "session.execute(create_statement)\n",
    "\n",
    "select_statement = \"\"\"SELECT artist_name, song_title, song_length FROM song_user_data_by_user_and_session_data WHERE user_id = %s AND session_id = %s\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidRequest",
     "evalue": "Error from server: code=2200 [Invalid query] message=\"Undefined column name song_length\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidRequest\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-db2e1894bfbd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mresult_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mselect_statement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m182\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresult_set\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/cassandra/cluster.cpython-38-darwin.so\u001b[0m in \u001b[0;36mcassandra.cluster.Session.execute\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/cassandra/cluster.cpython-38-darwin.so\u001b[0m in \u001b[0;36mcassandra.cluster.ResponseFuture.result\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mInvalidRequest\u001b[0m: Error from server: code=2200 [Invalid query] message=\"Undefined column name song_length\""
     ]
    }
   ],
   "source": [
    "with open(file, encoding = 'utf8') as f:\n",
    "    csvreader = csv.reader(f)\n",
    "    next (csvreader) #skip header\n",
    "    for line in csvreader:\n",
    "        \n",
    "        query = \"\"\"INSERT INTO song_user_data_by_user_and_session_data(user_id, session_id, session_item_number, artist_name, song_title,\n",
    "                user_first_name, user_last_name)\"\"\"\n",
    "        query = query + \"VALUES (%s, %s, %s, %s, %s, %s, %s)\"\n",
    "        \n",
    "        session.execute(query, (int(line[10]), int(line[8]), int(line[3]), line[0], line[9], line[4], line[4]))\n",
    "        \n",
    "result_set = session.execute(select_statement, (10, 182))\n",
    "\n",
    "for row in result_set:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Query 3: Give me every user name (first and last) in my music app history who listened to the song 'All Hands Against His Own'\n",
    "\n",
    "## In this case, song_title is the PARTITION KEY and user_id \\\n",
    "## is the CLUSTERING KEY, the request asks to retrieve the user name \\\n",
    "## by song title, so we have to set song_title as PARTITION KEY, but \\\n",
    "## more users can listen to the same song so we may have many INSERT with the \\\n",
    "## same key, Cassandra overwrites data with the same key so we need to add a CLUSTERING KEY \\\n",
    "## because we need to have a unique record but not to query on that. \\\n",
    "## Our complete PRIMARY KEY is composed by song_title, user_id \n",
    "\n",
    "create_statement = \"\"\"CREATE TABLE IF NOT EXISTS user_data_by_song_title (song_title TEXT,\n",
    "                    user_id INT,\n",
    "                    user_first_name TEXT,\n",
    "                    user_last_name TEXT,\n",
    "                    PRIMARY KEY((song_title), user_id))\"\"\"\n",
    "\n",
    "session.execute(create_statement)\n",
    "\n",
    "with open (file, encoding ='utf8') as f:\n",
    "    csvreader= csv.reader(f)\n",
    "    next (csvreader) #skip header\n",
    "    for line in csvreader:\n",
    "        \n",
    "        query = \"\"\"INSERT INTO user_data_by_song_title(song_title, user_id, user_first_name, user_last_name )\"\"\"\n",
    "        query = query + \"VALUES (%s, %s, %s, %s )\"\n",
    "\n",
    "        session.execute(query, (line[9], int(line[10]), line[1], line[4]))\n",
    "        \n",
    "select_statement = \"\"\"SELECT user_first_name, user_last_name FROM user_data_by_song_title WHERE song_title= %s \"\"\"\n",
    "        \n",
    "result_set = session.execute(select_statement, ('All Hands Against His Own', ))\n",
    "\n",
    "for row in result_set:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop the tables before closing out the sessions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_song_data_by_session = \"\"\"DROP TABLE song_data_by_session\"\"\"\n",
    "drop_song_user_data_by_user_and_session_data = \"\"\"DROP TABLE song_user_data_by_user_and_session_data\"\"\"\n",
    "drop_user_data_by_song_title = \"\"\"DROP TABLE user_data_by_song_title \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.execute(drop_song_data_by_session)\n",
    "session.execute(drop_song_user_data_by_user_and_session_data)\n",
    "session.execute(drop_user_data_by_song_title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Close the session and cluster connection \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.shutdown()\n",
    "cluster.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Process Ended')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
